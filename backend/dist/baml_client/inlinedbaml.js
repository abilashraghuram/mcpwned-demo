/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/
// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT41Mini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4.1-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\nclient<llm> CustomGPT41 {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4.1\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.89.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n\n    module_format \"esm\"\n}\n",
    "report_generator.baml": "// Types for playground diagram mock object\nclass PlaygroundNode {\n  id string\n  type string\n  position PlaygroundPosition\n  data PlaygroundNodeData\n}\n\nclass PlaygroundPosition {\n  x int\n  y int\n}\n\nclass PlaygroundNodeData {\n  label string\n  color string\n}\n\nclass PlaygroundEdge {\n  id string\n  source string\n  target string\n  animated true\n  style PlaygroundEdgeStyle\n}\n\nclass PlaygroundEdgeStyle {\n  stroke string\n  strokeWidth int\n}\n\nclass PlaygroundDiagramMock {\n  nodes PlaygroundNode[]\n  edges PlaygroundEdge[]\n  guardrails string[]\n  mcpTools string[]\n  scan_description string\n}\n\nclass PlaygroundToolsInput {\n  tools string[]\n  // Add more fields as needed for the tools input object\n}\n\nclass PlaygroundDiagramMockList {\n  diagrams PlaygroundDiagramMock[]\n}\n\n// Function to generate a mock playground diagram object from raw tools output\nfunction GeneratePlaygroundDiagramMock(rawToolsInput: PlaygroundToolsInput) -> PlaygroundDiagramMock {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    Read each of the tools in the input below. Analyze the control flow and data flow exploits that could occur with a subset of these tools. Specifically, search for tool chain calls that can lead to loop problems. Loops are a common source of bugs and errors in agentic systems. For example, an agent can:\n\n    - Get stuck in an infinite loop, consuming resources and causing the system to crash.\n    - Get stuck in a loop that causes it to perform an irreversible action, such as sending a message many times.\n    - Get stuck in a loop, requiring many expensive LLM calls, causing the system to run out of tokens or money.\n\n    Configure the PlaygroundPositions for the nodes such that their placement visually interprets the exploit being portrayed (e.g., loops should be visually apparent, safe paths should be clearly separated from exploit paths).\n\n    The nodes should always be connected in a way depicting a cycle, making loop problems visually apparent in the diagram.\n\n    Guardrail suggestions should always be centered around monitoring the chain of execution of tool calls.\n\n    Then, generate a set of React Flow nodes and edges representing the flow. The nodes and edges of the React Flow diagram must be correctly color coded as green to show safe paths and red to show exploit paths. List the affected tools, and propose guardrails to mitigate the exploits, especially those related to loop problems. Populate the scan_description string with a concise 5 word summary of the exploit being displayed in the diagram.  Return the result in the following format:\n\n    {{ ctx.output_format }}\n\n    TOOLS INPUT: {{ rawToolsInput }}\n\n    OUTPUT: {{ ctx.output_format }}\n  \"#\n}\n\n// Function to generate three mock playground diagram objects\nfunction GenerateThreePlaygroundDiagramMocks(rawToolsInput: PlaygroundToolsInput) -> PlaygroundDiagramMockList {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n    Read the tools in the input below. Generate three distinct PlaygroundDiagramMock objects, each representing a different scenario of control flow and data flow exploits using subsets of these tools. For each, specifically search for tool chain calls that can lead to loop problems. Loops are a common source of bugs and errors in agentic systems. For example, an agent can:\n\n    - Get stuck in an infinite loop, consuming resources and causing the system to crash.\n    - Get stuck in a loop that causes it to perform an irreversible action, such as sending a message many times.\n    - Get stuck in a loop, requiring many expensive LLM calls, causing the system to run out of tokens or money.\n\n    Configure the PlaygroundPositions for the nodes such that their placement visually interprets the exploit being portrayed (e.g., loops should be visually apparent, safe paths should be clearly separated from exploit paths).\n\n    The nodes should always be connected in a way depicting a cycle, making loop problems visually apparent in the diagram.\n\n    Guardrail suggestions should always be centered around monitoring the chain of execution of tool calls.\n\n    For each scenario, generate React Flow nodes and edges. The nodes and edges of the React Flow diagram must be correctly color coded as green to show safe paths and red to show exploit paths. List affected tools, and propose guardrails to mitigate the exploits, especially those related to loop problems. The list of affected tools should exactly match the nodes depicted in the react flow diagram. Populate the scan_description string with a concise 5 word summary of the exploit being displayed in the diagram. Return the result as a PlaygroundDiagramMockList containing three PlaygroundDiagramMock objects.\n    \n   {{ ctx.output_format }}\n    \n    {{ _.role('user') }}\n    {{ rawToolsInput }}\n  \"#\n}\n\n\n\n// Function to generate three mock playground diagram objects\nfunction GenerateSixPlaygroundDiagramMocks(rawToolsInput: PlaygroundToolsInput) -> PlaygroundDiagramMockList {\n  client \"openai/gpt-4.1\"\n  prompt #\"\n  Create one scenario for each theme below (exactly six in total).\n  Describe them in your diagrams and also include the numbered list below verbatim in your prompt output so the downstream AI clearly understands what to look for:\n    1.\tInfinite‑Loop Resource Exhaustion\n  Agent repeatedly calls tools in a cycle, consuming CPU / memory until crash.\n    2.\tIrreversible‑Action Loop\n  Loop triggers a non‑idempotent tool (e.g., send_email, make_payment) many times.\n    3.\tToken‑Drain Loop\n  Loop issues expensive LLM/tool calls, quickly burning through token limits or money.\n    4.\tSensitive‑Data Exfiltration\n  Data from an internal source is routed—intentionally or accidentally—to an external sink (e.g., http_post, send_email).\n    5.\tPrompt‑Injection Hijack\n  External service injects malicious content that tricks the agent into executing unintended tool calls.\n    6.\tPrivilege‑Escalation / Destructive‑Action\n  Agent chain ends in a dangerous tool (delete_file, bash rm -rf, wire_funds) without verifying authorization.\n\n  What Each PlaygroundDiagramMock Must Contain:\n  Correct react_flow_nodes and react_flow_edges where you make hijack visually obvious. Color all edges/nodes green for safe paths and red for exploit paths.\n  The color of the node should be a string hex code like #F87171\n  The stroke of the edge shoulkd be a string hex code like #22c55e\n  The strokeWidth of the edge should be an int like 2\n \n  Intuitive playground_positions that visually emphasize the loop or the data‑leak path (e.g., circular layout for loops, forked graph for exfiltration)\n  Exact and precise list of affected_tools that are depicted in the graph, in the order they appear.\n  Exact and precise guardrail_suggestions that have Concrete, actionable mitigations that focus on monitoring the chain of execution, plus input/output validation, rate‑limiting, and role‑based authorization as relevant to the theme.\n  Exact and precise scan_description that is a always a Five‑word summary of the exploit (e.g., \"Infinite LLM call token drain\").\n\n  General Instructions\n\t•\tSearch the tool list for combinations that naturally demonstrate each exploit theme.\n\t•\tAlways form at least one cycle to highlight loop problems.\n\t•\tKeep descriptions concise but precise.\n\n   {{ ctx.output_format }}\n    \n    {{ _.role('user') }}\n    {{ rawToolsInput }}\n  \"#\n}",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n",
};
export const getBamlFiles = () => {
    return fileMap;
};
